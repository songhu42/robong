3. 이미지 채널 변경
BGR 순서의 이미지 데이터는 기본적으로 RGB 순서를 따르는 이미지 뷰어와 호환되지 않는다.
BGR 순서의 채널을 RGB순서로 변경해야한다.

import cv2
from pop import Util 

Util.enable_imshow()
imgOrigin = cv2.imread("img.jpg", cv2.IMREAD_COLOR)

b, g, r = cv2.split(imgOrigin)  # 이미지 데이터를  채널별로 분리
imgNew = cv2.merge([r, g, b])  # 다시 묶는다.

cv2.imshow("Origin", imgOrigin)
cv2.imshow("New", imgNew)

cv2.waitKey(0) // 키입력 대기
cv2.destroyAllWindows() # 모든창 닫기

원본 이미지와 비교했을 때 Red - Blue 채널이 바뀐 이미지가 표시된다.


4. 이미지 저장
imwrite()메소드는 BGR 순서의 배열을 다른 이미지 뷰어와 호환성을 유지하기 위해 RGB 순서로 바꿔 이미지 파일로 저장한다.

import cv2

imgOrigin = cv2.imread("img.jpg", cv2.IMREAD_COLOR) 
imgGray = cv2.imread("img.jpg", cv2.IMREAD_GRAYSCALE)

cv2.imwrite("img.jpg", imgColor)
cv2.imwrite("imgGray.jpg", imgGray)

이미지 파일이 생성된다.

5. GStreamer 프레임워크
카메라나 파일에서 비디오 프레임을 읽을 때에는 GStreamer 프레임워크와 VideoCapture 클래스를 사용한다.
GStreamer를 사용하려면 해상도, 프레임, 색상 채널 등의 설정이 필요하다.
VideoCapture클래스 생성자로 입력하면 카메라에 접근할 수 있다.

import cv2
from pop import Util

cam = "nvarguscamerasrc ! video/x-raw(memory:NVMM), width=(int)640, height=(int)480, format=(string)NV12, framerate=(fraction)30/1 ! nvvidconv flip-method=0 ! video/x-raw, width=(int)640, height=(int)480, format=(string)BGRx ! videoconvert ! video/x-raw, format=(string)BGR ! appsink"
cv2.VideoCapture(cam, cv2.CAP_GSTREAMER)

<VideoCapture 0x7f94706e30> 

설정하는 문장이 너무 길어 매번 입력하기 힘드므로 Pop.Util 라이브러리에 미리 정의되어 있는 gstreamer() 메소드를 사용한다.

cam = Util.gstrmer(width=640, height=480, fps=30, flip=0)
cv2.VideoCapture(cam, cv2.CAP_GSTREAMER)

<VideoCapture 0x7f54407f30> 


6. 카메라 캡쳐

다음 예제는 VideoCapture 클래스를 이용해 카메라 데이터를 640x480 해상도로 창에 표시하는 예제이다.

import cv2
from pop import Util
Util.enable_imshow()

cam = Util.gstrmer(width=640, height=480)
camera = cv2.VideoCapture(cam, cv2.CAP_GSTREAMER)

if not camera.isOpened():
    print("Not found camera")

width = camera.get(cv2.CAP_PROP_FRAME_WIDTH)
height = camera.get(cv2.CAP_PROP_FRAME_HEIGHT)

print("init width: %d, init height: %d" % (width,height))

[결과]
init width: 640, init height: 480

for _ in range(120):
    ret, frame = camera.read()
    if not ret:
        break

    cv2.imshow("soda", frame)


camera.release()
cv2.destroyAllWindows()

카메라가 보이지 않는다면 앞의 실습에서 카메라를 사용중일 때 동작하지 않을 수 있다.
카메라를 사용후, release()를 해줘야 한다.

기존 실습예제를 shutdown 해준다.


7. 비디오 저장

import cv2
from pop import Util
Util.enable_imshow()

cam = Util.gstrmer(width=640, height=480)
camera = cv2.VideoCapture(cam, cv2.CAP_GSTREAMER)

if not camera.isOpened():
    print("Not found camera")

fourcc = cv2.VideoWriter_fourcc(*"X264")
out = cv2.VideoWriter("soda.avi", fourcc, 30, (640,480))

for _ in range(120):
    ret, frame = camera.read()
    framGray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  

    out.write(frame)
    cv2.imshow("soda", framGray)

camera.release()

cv2.destroyAllWindows()


8. 외곽선 검출
OpenCV의 zosl 엣지 검술 알고리즘은 잡음에 민감하지 않으며 명확한 외곽선을 검출하는데 목적을 두고 있는 알고리즘이다. 
캐니 엣지 검출은 Canny() 메소드를 통해 사용가능하다.

import cv2
from pop import Util
Util.enable_imshow()

cam = Util.gstrmer(width=640, height=480)
camera = cv2.VideoCapture(cam, cv2.CAP_GSTREAMER)

if not camera.isOpened():
    print("Not found camera")

for _ in range(120):
    ret, frame = camera.read()
    img = cv2.Canny(frame,100, 200) # threshold 최소값 100, 최대값 200 으로 설정

    cv2.imshow("soda", img) 

camera.release()
cv2.destroyAllWindows()


read() 메소드는 한 프레임씩 반환하므로 for문을 이용하여 120개의 프레임을 읽어온다. 
Canny()메소드를 통해 프레임에서 외곽선을 검출한다.
Canny() 메소드에서는 8-bit로 변환 후 임계치 범위를 벗어나는 값들을 제거한다.
이렇게 변환한 이미지를 창에 출력한다.


9. 얼굴 인식 - Haar Cascades
OpenCV는 얼굴인식 관련 데이터 모델과 얼굴인식 알고리즘을 기본 제공한다.
이를 활용하여 카메라를 통해 입력 되는 영상에서 사람 얼굴을 인진하는 프로그램을 작성해 보도록 하겠다.

Haar Cascade 는 머신러닝 기반의 객체 검출 알고리즘이다.
이미지나 비디오에서 객체를 검출할 때 사용된다.
직사각형 영역으로 구성되는 특징을 사용하기 때문에 픽셀 단위로 객체를 검출하는 방법보다 동작 속도 측면에서 따른 검출 속도를 보인다.
검출하기 위한 객체가 포함된 이미지와 포함되지 않은 이미지를 활용하여 특징 분류기를 통해 학습을 진행하고, 학습이 완료되면 분류기를 활용하여 객체를 검출한다.

이 알고리즘은 크게 4단계로 분류할 수 있다.

1) Haar Feature Selection : 특징 선택
사각형 형태의 커널을 가지고 특징 계산을 위해 이미지 전체를 스캔한다.
이미지를 스캔하여 이동하는 인접한 사각 영역내에 있는 픽셀의 합의 차이를 활용

2) Integral Images : 적분 이미지
사각 영역 내부의 픽셀들을 빠르게 더하고 연산하기 위해 적분 이미지를 사용

3) Adaboost Training : 특징 학습
선택한 특징을 활용하여 학습을 진행
선택된 특징 중 객체를 검출하기 위한 특징을 선별
선별된 특징을 이용하여 학습에 사용되는 이미지에 특징을 적용
잘못 분류될 가능성이 있기 때문에 에러율이 낮은 특징을 선택

4) Cascade Classifier : 특징 분류
학습이 완료되면 이력 이미지를 통해 객체를 검출
입력 이미지에서 객체가 있는 영역인지 단계별로 체크하여 검출

import cv2
from pop import Util
Util.enable_imshow()

haar_face= '/usr/local/share/opencv4/haarcascades/haarcascade_frontalface_default.xml'
face_cascade = cv2.CascadeClassifier(haar_face) # 분류기를 로드한다.

cam = Util.gstrmer(width=640, height=480)
camera = cv2.VideoCapture(cam, cv2.CAP_GSTREAMER)

if not camera.isOpened():
    print("Not found camera")

for _ in range(300):
    ret, img = camera.read()
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    faces= face_cascade.detectMultiScale(gray, scaleFactor=1.3 ,minNeighbors=1,minSize=(100,100))

    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)

    cv2.imshow('img',img)

cam.release()
cv2.destroyAllWindows()


 입력받은 프레임을 회색톤으로 변환하고 detectMulitiScale() 메소드를 이용해 얼굴을 검출한다.
scaleFactor의 값을 줄일 경우 정호가도가 늘어날 수 가 있지만 속도가 느려지며, 
minNeighbors의 값을 늘릴 경우에도 정확도가 늘어날 수 있지만 해상도가 떨어지는 이미지에서는 검출에 실패할 수 도 있다.    
검출된 위치에 파란색 사각형을 그려 화면에 출력한다.

안녕? 난 로라야~